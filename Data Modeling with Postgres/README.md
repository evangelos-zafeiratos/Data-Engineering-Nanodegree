# Data Modeling with Postgres


The project is modeling user activity data generated in a music streaming app (Sparkify). The objective is to build an ETL to convert the logs and song datasets into a relational database optimised for queries related to song play analysis.

## Project Structure

``` 
Data Modeling with Postgres
|____data			# Dataset
| |____log_data
| | |____...
| |____song_data
| | |____...
|
|____Jupyter notebook       # notebook for developing and testing ETL
| |____etl.ipynb            # developing ETL builder
| |____test.ipynb           # testing ETL builder
| |____cheat-sheet.pdf
|
|____src			# source code
| |____etl.py			    # ETL builder
| |____sql_queries.py		    # ETL query helper functions
| |____create_tables.py		    # database/table creation script
```

## How to Run Project

 Using a Python terminal :
 
- Execute the command **"python create_tables.py"** <br>
This command will create the database, the connection to the database and all the tabes that have been designed during the data modeling process.
- Execute the command **"python etl.py"** <br>
This command will fetch all the data files from songs & log data and will execute the etl and load the corresponding values to the already created tables.

On a Jupyter notebook: 

- Open the **"test.ipynb"** file and run the magic commands listed <br>
This is to verify that the tables in the database have been loaded with the data

## Data Modeling

First type of dataset is named song_dataset, it is given in JSON format and contains metadata about a song and the artist of that song. The available data fields on that file are the following : 

```
- artist_id	
- artist_latitude	
- artist_location	
- artist_longitude	
- artist_name	
- duration	
- num_songs	
- song_id	
- title	
- year
```

Second type of dataset is named log_dataset, it is given in JSON format and contains activity logs generated by an event simulator. The available data fields on that file are the following :

```
- artist	
- auth	
- firstName	
- gender	
- itemInSession	
- lastName	
- length	
- level	
- location	
- method	
- page	
- registration	
- sessionId	
- song	
- status	
- ts	
- userAgent	
- userId
```

"Sparkify" relational database is based on Star Schema and it consists of the following tables

### Fact table
```
songplays
	- songplay_id 	PRIMARY KEY
	- start_time 	REFERENCES time (start_time)
	- user_id	REFERENCES users (user_id)
	- level
	- song_id 	REFERENCES songs (song_id)
	- artist_id 	REFERENCES artists (artist_id)
	- session_id
	- location
	- user_agent
```

### Dimension table
```
users
	- user_id 	PRIMARY KEY
	- first_name
	- last_name
	- gender
	- level

songs
	- song_id 	PRIMARY KEY
	- title
	- artist_id
	- year
	- duration

artists
	- artist_id 	PRIMARY KEY
	- name
	- location
	- latitude
	- longitude

time
	- start_time 	PRIMARY KEY
	- hour
	- day
	- week
	- month
	- year
	- weekday
```


## ETL Pipeline
### etl.py
ETL pipeline builder

1. `process_data`
	* Iterating dataset to apply `process_song_file` and `process_log_file` functions
2. `process_song_file`
	* Process song dataset to insert record into _songs_ and _artists_ dimension table
3. `process_log_file`
	* Process log file to insert record into _time_ and _users_ dimensio table and _songplays_ fact table

### create_tables.py
Creating Fact and Dimension table schema

1. `create_database`
2. `drop_tables`
3. `create_tables`

### sql_queries.py
Helper SQL query statements for `etl.py` and `create_tables.py`

1. `*_table_drop`
2. `*_table_create`
3. `*_table_insert`
4. `song_select`
